{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae6e369a-e738-4f65-aa91-b03519116799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE RATING IS 0-5 INTEGER ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93321c0a-0947-42dc-9c4d-56ffa6ef5d92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T17:28:31.829514500Z",
     "start_time": "2024-12-02T17:28:27.913017100Z"
    }
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scipy.optimize\n",
    "from sklearn import svm\n",
    "import numpy\n",
    "import string\n",
    "import random\n",
    "import string\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.optimize import minimize\n",
    "from itertools import islice\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52865c25-9f4d-4457-9010-b8233ae2dd57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T17:28:31.838740700Z",
     "start_time": "2024-12-02T17:28:31.831794Z"
    }
   },
   "outputs": [],
   "source": [
    "def assertFloat(x):\n",
    "    assert type(float(x)) == float\n",
    "\n",
    "def assertFloatList(items, N):\n",
    "    assert len(items) == N\n",
    "    assert [type(float(x)) for x in items] == [float]*N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d8344d7-1767-4f40-8fb5-da3c5a715342",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T17:28:31.839242800Z",
     "start_time": "2024-12-02T17:28:31.833482100Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d33ac2cc-c2d4-4d0c-9d69-feaa1675ea9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T17:28:31.846791800Z",
     "start_time": "2024-12-02T17:28:31.838740700Z"
    }
   },
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3477cac-d624-464e-beba-4d82df60c5a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T17:28:31.846791800Z",
     "start_time": "2024-12-02T17:28:31.843216500Z"
    }
   },
   "outputs": [],
   "source": [
    "def readCSV(path):\n",
    "    with open(path, mode='r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        # Skip the header row\n",
    "        next(reader, None)\n",
    "        # Loop through the rows\n",
    "        for row in reader:\n",
    "            # Extract the first 4 columns\n",
    "            u,i,d,r = row[:4]\n",
    "            yield u, i, d, float(r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### This is the Alternative Model\n",
    "Feel free to play with the data! To avoid merge conflicts though either duplicate the file or use a different branch.\n",
    "If there are any issues or fixes to stuff that I've done lmk.\n",
    "\n",
    "The baseline is just here to chill around. \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d039e8535868cdda"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a23e9c98-afb4-49c2-817b-8dd7342ee877",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T17:28:34.420474500Z",
     "start_time": "2024-12-02T17:28:32.059431700Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = []\n",
    "ratings_dict = defaultdict(int)\n",
    "itemsPerUser = defaultdict(set)\n",
    "usersPerItem = defaultdict(set)\n",
    "global_fallback_rating = 0\n",
    "for l in readCSV(\"data/interactions_train.csv\"):\n",
    "    train_dataset.append(l)\n",
    "    user, recipe, data, rating = l\n",
    "    itemsPerUser[user].add(recipe)\n",
    "    usersPerItem[recipe].add(user)\n",
    "    global_fallback_rating += rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d44c4a19-23dc-4bc8-83cd-fc07124f5630",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T17:28:34.430570800Z",
     "start_time": "2024-12-02T17:28:34.422093700Z"
    }
   },
   "outputs": [],
   "source": [
    "global_fallback_rating = global_fallback_rating / len(train_dataset)\n",
    "global_fallback_rating\n",
    "def baseline_predictor(user, item, date):\n",
    "    return global_fallback_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cbed53a-81a8-4af0-a094-fa3e529d5bdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T17:28:34.457911900Z",
     "start_time": "2024-12-02T17:28:34.426585600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline MSE: 1.8138061805801156\n"
     ]
    }
   ],
   "source": [
    "validation_dataset = []\n",
    "validation_reals = []\n",
    "validation_preds = []\n",
    "for l in readCSV(\"data/interactions_validation.csv\"):\n",
    "    validation_dataset.append(l)\n",
    "    user, recipe, date, rating = l\n",
    "    validation_reals.append(rating)\n",
    "    validation_preds.append(baseline_predictor(user, recipe, date))\n",
    "print(f'baseline MSE: {mean_squared_error(validation_reals, validation_preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Alternative Model\n",
    "\n",
    "This is a simple SVDpp using purely relationships between rated recipes and user ids, similar to the data format of assignment 1. \n",
    "The n_factors yield the best result at 1 from Cross-Validation. Any substantially higher number (e.g 50) will take too much time to run given a specific run time with the dataset. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cbdcd252171e478c"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2fa47a4a-856a-46a3-bf24-9bb420c1daf1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T02:00:52.063515600Z",
     "start_time": "2024-12-03T01:58:14.154071900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  recipe        date  rating      u       i\n",
      "0     2046    4684  2000-02-25     5.0  22095   44367\n",
      "1     2046     517  2000-02-25     5.0  22095   87844\n",
      "2     1773    7435  2000-03-13     5.0  24732  138181\n",
      "3     1773     278  2000-03-13     4.0  24732   93054\n",
      "4     2046    3431  2000-04-07     5.0  22095  101723\n",
      "5     2046   13307  2000-05-21     5.0  22095  134551\n",
      "6     2312     780  2000-09-12     5.0   1674  127175\n",
      "7     2312   51964  2000-09-26     5.0   1674  151793\n",
      "8     2312    1232  2000-10-17     4.0   1674   15498\n",
      "9     2312    4397  2000-10-17     5.0   1674   14380\n",
      "MSE: 0.8488\n",
      "MSE on train / test split: 0.8488063963281915\n",
      "MSE on validation set: 1.549737618724458\n",
      "MSE on test set: 1.651565567137675\n"
     ]
    }
   ],
   "source": [
    "#This is a model using svdpp to compare our original model to\n",
    "import gzip\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import csv\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import SVDpp\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "#using pandas to make display a bit easier to debug\n",
    "df = pd.read_csv(\"data/interactions_train.csv\", names=['user_id', 'recipe', 'date', 'rating', \"u\", \"i\"], skiprows = 1 )\n",
    "print(df[0:10])\n",
    "df['rating'] = df['rating'].astype(int)  \n",
    "reader = Reader(rating_scale=(0, 5))\n",
    "data = Dataset.load_from_df(df[['user_id', 'recipe','rating']], reader)\n",
    "trainset, testset = train_test_split(data, test_size=0.001)\n",
    "model = SVDpp(n_factors=1, lr_all=0.01, reg_all = 0.1)\n",
    "model.fit(trainset)\n",
    "\n",
    "#validation\n",
    "pairs = pd.read_csv('data/interactions_validation.csv', names=['user_id', 'recipe', 'date', 'rating', \"u\", \"i\"], skiprows=1)\n",
    "predictions = []\n",
    "for _, row in pairs.iterrows():\n",
    "    user = row['user_id']\n",
    "    rec = row['recipe']\n",
    "    pred = model.predict(user, rec).est\n",
    "    predictions.append(pred - 0.25)\n",
    "\n",
    "#test\n",
    "pairsT = pd.read_csv('data/interactions_test.csv', names=['user_id', 'recipe', 'date', 'rating', \"u\", \"i\"], skiprows=1)\n",
    "predictionsT = []\n",
    "for _, row in pairsT.iterrows():\n",
    "    user = row['user_id']\n",
    "    rec = row['recipe']\n",
    "    pred = model.predict(user, rec).est\n",
    "    predictionsT.append(pred- 0.25)\n",
    "    \n",
    "    \n",
    "pairs['prediction'] = predictions\n",
    "pairsT['prediction'] = predictionsT\n",
    "\n",
    "predictions_ttest = model.test(testset)\n",
    "mse = accuracy.mse(predictions_ttest)\n",
    "print(f'MSE on train / test split: {mse}')\n",
    "\n",
    "validation_actual = pairs['rating'].astype(float)  \n",
    "validation_predicted = pairs['prediction']        \n",
    "validation_mse = np.mean((validation_actual - validation_predicted) ** 2)\n",
    "print(f'MSE on validation set: {validation_mse}')\n",
    "\n",
    "test_actual = pairsT['rating'].astype(float)\n",
    "test_predicted = pairsT['prediction']\n",
    "test_mse = np.mean((test_actual - test_predicted) ** 2)\n",
    "print(f'MSE on test set: {test_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on validation set: 1.5500290567556492\n",
      "MSE on test set: 1.651565567137675\n"
     ]
    }
   ],
   "source": [
    "#this is to play around with shifters\n",
    "\n",
    "testpr = []\n",
    "for i in predictions:\n",
    "    testpr.append(i)\n",
    "ttestpr = []\n",
    "for i in predictionsT:\n",
    "    ttestpr.append(i)\n",
    "    \n",
    "nvalidation_actual = pairs['rating'].astype(float)\n",
    "nvalidation_predicted = testpr\n",
    "nvalidation_mse = np.mean((nvalidation_actual - nvalidation_predicted) ** 2)\n",
    "print(f'MSE on validation set: {nvalidation_mse}')\n",
    "\n",
    "\n",
    "ntest_actual = pairsT['rating'].astype(float)\n",
    "ntest_predicted = ttestpr\n",
    "ntest_mse = np.mean((ntest_actual - ntest_predicted) ** 2)\n",
    "print(f'MSE on test set: {ntest_mse}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-03T03:51:02.245858700Z",
     "start_time": "2024-12-03T03:51:02.216537200Z"
    }
   },
   "id": "30838fb0f1c43926"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[32], line 22\u001B[0m\n\u001B[0;32m     16\u001B[0m param_grid \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m     17\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mn_factors\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;241m7\u001B[39m, \u001B[38;5;241m15\u001B[39m],\n\u001B[0;32m     18\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlr_all\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;241m0.002\u001B[39m, \u001B[38;5;241m0.005\u001B[39m, \u001B[38;5;241m0.01\u001B[39m],\n\u001B[0;32m     19\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mreg_all\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;241m0.2\u001B[39m, \u001B[38;5;241m0.3\u001B[39m]\n\u001B[0;32m     20\u001B[0m }\n\u001B[0;32m     21\u001B[0m rs \u001B[38;5;241m=\u001B[39m RandomizedSearchCV(SVDpp, param_grid, measures\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrmse\u001B[39m\u001B[38;5;124m'\u001B[39m], cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, n_iter\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m)  \u001B[38;5;66;03m# Only test 10 random combinations\u001B[39;00m\n\u001B[1;32m---> 22\u001B[0m rs\u001B[38;5;241m.\u001B[39mfit(data)\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBest NF\u001B[39m\u001B[38;5;124m\"\u001B[39m, rs\u001B[38;5;241m.\u001B[39mbest_params[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrmse\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m     24\u001B[0m results \u001B[38;5;241m=\u001B[39m rs\u001B[38;5;241m.\u001B[39mcv_results\n",
      "File \u001B[1;32m~\\.conda\\envs\\cse158\\Lib\\site-packages\\surprise\\model_selection\\search.py:104\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m     90\u001B[0m cv \u001B[38;5;241m=\u001B[39m get_cv(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcv)\n\u001B[0;32m     92\u001B[0m delayed_list \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     93\u001B[0m     delayed(fit_and_score)(\n\u001B[0;32m     94\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39malgo_class(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    102\u001B[0m     )\n\u001B[0;32m    103\u001B[0m )\n\u001B[1;32m--> 104\u001B[0m out \u001B[38;5;241m=\u001B[39m Parallel(\n\u001B[0;32m    105\u001B[0m     n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_jobs,\n\u001B[0;32m    106\u001B[0m     pre_dispatch\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpre_dispatch,\n\u001B[0;32m    107\u001B[0m     verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mjoblib_verbose,\n\u001B[0;32m    108\u001B[0m )(delayed_list)\n\u001B[0;32m    110\u001B[0m (test_measures_dicts, train_measures_dicts, fit_times, test_times) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mout)\n\u001B[0;32m    112\u001B[0m \u001B[38;5;66;03m# test_measures_dicts is a list of dict like this:\u001B[39;00m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;66;03m# [{'mae': 1, 'rmse': 2}, {'mae': 2, 'rmse': 3} ...]\u001B[39;00m\n\u001B[0;32m    114\u001B[0m \u001B[38;5;66;03m# E.g. for 5 splits, the first 5 dicts are for the first param\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    121\u001B[0m \u001B[38;5;66;03m# (n_parameters_combinations, n_splits). This way we can easily compute\u001B[39;00m\n\u001B[0;32m    122\u001B[0m \u001B[38;5;66;03m# the mean and std dev over all splits or over all param comb.\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\cse158\\Lib\\site-packages\\joblib\\parallel.py:1918\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1916\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_sequential_output(iterable)\n\u001B[0;32m   1917\u001B[0m     \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[1;32m-> 1918\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(output)\n\u001B[0;32m   1920\u001B[0m \u001B[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001B[39;00m\n\u001B[0;32m   1921\u001B[0m \u001B[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001B[39;00m\n\u001B[0;32m   1922\u001B[0m \u001B[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001B[39;00m\n\u001B[0;32m   1923\u001B[0m \u001B[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001B[39;00m\n\u001B[0;32m   1924\u001B[0m \u001B[38;5;66;03m# callback.\u001B[39;00m\n\u001B[0;32m   1925\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n",
      "File \u001B[1;32m~\\.conda\\envs\\cse158\\Lib\\site-packages\\joblib\\parallel.py:1847\u001B[0m, in \u001B[0;36mParallel._get_sequential_output\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1845\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_batches \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1846\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m-> 1847\u001B[0m res \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1848\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_completed_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1849\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprint_progress()\n",
      "File \u001B[1;32m~\\.conda\\envs\\cse158\\Lib\\site-packages\\surprise\\model_selection\\validation.py:176\u001B[0m, in \u001B[0;36mfit_and_score\u001B[1;34m(algo, trainset, testset, measures, return_train_measures)\u001B[0m\n\u001B[0;32m    174\u001B[0m fit_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_fit\n\u001B[0;32m    175\u001B[0m start_test \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m--> 176\u001B[0m predictions \u001B[38;5;241m=\u001B[39m algo\u001B[38;5;241m.\u001B[39mtest(testset)\n\u001B[0;32m    177\u001B[0m test_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_test\n\u001B[0;32m    179\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m return_train_measures:\n",
      "File \u001B[1;32m~\\.conda\\envs\\cse158\\Lib\\site-packages\\surprise\\prediction_algorithms\\algo_base.py:160\u001B[0m, in \u001B[0;36mAlgoBase.test\u001B[1;34m(self, testset, verbose)\u001B[0m\n\u001B[0;32m    142\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Test the algorithm on given testset, i.e. estimate all the ratings\u001B[39;00m\n\u001B[0;32m    143\u001B[0m \u001B[38;5;124;03min the given testset.\u001B[39;00m\n\u001B[0;32m    144\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    156\u001B[0m \u001B[38;5;124;03m    that contains all the estimated ratings.\u001B[39;00m\n\u001B[0;32m    157\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    159\u001B[0m \u001B[38;5;66;03m# The ratings are translated back to their original scale.\u001B[39;00m\n\u001B[1;32m--> 160\u001B[0m predictions \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    161\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict(uid, iid, r_ui_trans, verbose\u001B[38;5;241m=\u001B[39mverbose)\n\u001B[0;32m    162\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m (uid, iid, r_ui_trans) \u001B[38;5;129;01min\u001B[39;00m testset\n\u001B[0;32m    163\u001B[0m ]\n\u001B[0;32m    164\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m predictions\n",
      "File \u001B[1;32m~\\.conda\\envs\\cse158\\Lib\\site-packages\\surprise\\prediction_algorithms\\algo_base.py:161\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    142\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Test the algorithm on given testset, i.e. estimate all the ratings\u001B[39;00m\n\u001B[0;32m    143\u001B[0m \u001B[38;5;124;03min the given testset.\u001B[39;00m\n\u001B[0;32m    144\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    156\u001B[0m \u001B[38;5;124;03m    that contains all the estimated ratings.\u001B[39;00m\n\u001B[0;32m    157\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    159\u001B[0m \u001B[38;5;66;03m# The ratings are translated back to their original scale.\u001B[39;00m\n\u001B[0;32m    160\u001B[0m predictions \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m--> 161\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict(uid, iid, r_ui_trans, verbose\u001B[38;5;241m=\u001B[39mverbose)\n\u001B[0;32m    162\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m (uid, iid, r_ui_trans) \u001B[38;5;129;01min\u001B[39;00m testset\n\u001B[0;32m    163\u001B[0m ]\n\u001B[0;32m    164\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m predictions\n",
      "File \u001B[1;32m~\\.conda\\envs\\cse158\\Lib\\site-packages\\surprise\\prediction_algorithms\\algo_base.py:102\u001B[0m, in \u001B[0;36mAlgoBase.predict\u001B[1;34m(self, uid, iid, r_ui, clip, verbose)\u001B[0m\n\u001B[0;32m    100\u001B[0m details \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m    101\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 102\u001B[0m     est \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimate(iuid, iiid)\n\u001B[0;32m    104\u001B[0m     \u001B[38;5;66;03m# If the details dict was also returned\u001B[39;00m\n\u001B[0;32m    105\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(est, \u001B[38;5;28mtuple\u001B[39m):\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.model_selection import RandomizedSearchCV\n",
    "'''param_grid = {\n",
    "    'n_factors': [7, 15],  \n",
    "    'lr_all': [0.005, 0.01],\n",
    "    'reg_all': [0.1, 0.2]\n",
    "}\n",
    "gs = GridSearchCV(SVDpp, param_grid, measures=['rmse'], cv=2)\n",
    "gs.fit(data)\n",
    "\n",
    "results = gs.cv_results\n",
    "'''\n",
    "#randomized CV to cut processing time\n",
    "param_grid = {\n",
    "    'n_factors': [7, 15],\n",
    "    'lr_all': [0.002, 0.005, 0.01],\n",
    "    'reg_all': [0.2, 0.3]\n",
    "}\n",
    "rs = RandomizedSearchCV(SVDpp, param_grid, measures=['rmse'], cv=3, n_iter=10)  # Only test 10 random combinations\n",
    "rs.fit(data)\n",
    "print(\"Best NF\", rs.best_params['rmse'])\n",
    "results = rs.cv_results\n",
    "\n",
    "for params, mean_rmse, std_rmse in zip(results['params'], results['mean_test_rmse'], results['std_test_rmse']):\n",
    "    print(f\"Params: {params}, Mean RMSE: {mean_rmse:.4f}, Std Dev RMSE: {std_rmse:.4f}\")\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-02T19:20:59.181468800Z",
     "start_time": "2024-12-02T19:09:26.054478900Z"
    }
   },
   "id": "d68e45489a43e361"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6988c6890a36b698"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
